<h3>Neural Machine Translation</h3>

<p>This work builds upon the neural machine translation system built as a sequence-to-sequence example by Google Tensorflow. The goal of this project is to create a much more robust architecture
that speaks to Tensorflow >1.0. The vanilla seq2seq architecture in the model here uses residually-connected bidirectional encoders and decoders. Embedding replacement via FastText is around the corner as well.</p>

<p>This project is in heavy development now but check back in the coming weeks. My goal is to use it as a teaching tool for building NMT's from scratch but I want to make sure it at least mirrors the Tensorflow tutorial for now so others can compare them side-by-side.</p>
